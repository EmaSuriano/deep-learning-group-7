{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ec93f2f-5a99-4b2a-820f-6baa27104f7b",
   "metadata": {},
   "source": [
    "### Estructura del Proyecto Revisada\n",
    "\n",
    "1. **Preparación de los Datos**\n",
    "   - **Organización de Imágenes**: Las imágenes reales ya están clasificadas en carpetas según la postura de yoga, y las imágenes SVG simples también están etiquetadas. Se asegurará que ambas fuentes de datos estén correctamente organizadas y sean accesibles.\n",
    "   - **Redimensionamiento y Normalización**: Las imágenes tendrán diferentes dimensiones y formatos, así que las redimensionaremos a un tamaño estándar (por ejemplo, 224x224 píxeles) y las normalizaremos para que todos los valores de píxel estén en el rango [0, 1].\n",
    "   - **División del Conjunto de Datos**: Combinar las imágenes reales y SVG en un solo conjunto de datos, dividiéndolas en conjuntos de entrenamiento, validación y prueba, garantizando una proporción equilibrada de posturas en cada conjunto.\n",
    "\n",
    "2. **Aumento de Datos (Data Augmentation)**\n",
    "   - **Imágenes Reales**: Aplicar técnicas de aumento como rotación, cambios de escala, espejado horizontal, y variaciones de brillo/contraste para aumentar la variabilidad y robustez del modelo frente a condiciones de iluminación y perspectiva.\n",
    "   - **Imágenes SVG**: Convertir los SVG en imágenes rasterizadas si es necesario y aplicar variaciones simples para simular diferentes ángulos y tamaños.\n",
    "\n",
    "3. **Diseño de la Arquitectura de la CNN**\n",
    "   - **Uso de Doble Entrada**: Considerar una arquitectura que pueda manejar tanto las imágenes reales como las SVG (por ejemplo, mediante un enfoque multi-input o concatenando las salidas de dos redes). Esto permitirá que el modelo aprenda características tanto de las imágenes detalladas como de las representaciones simplificadas.\n",
    "   - **Definición de Capas**: Definir las capas convolucionales, de pooling, y fully connected, ajustando hiperparámetros como el número de filtros, tamaño de kernel, y funciones de activación (como ReLU).\n",
    "   - **Función de Pérdida y Optimizador**: Seleccionar una función de pérdida adecuada para clasificación (como `categorical_crossentropy`) y un optimizador (como Adam).\n",
    "\n",
    "4. **Entrenamiento del Modelo**\n",
    "   - **Entrenamiento Híbrido**: Entrenar el modelo usando tanto las imágenes reales como las SVG para asegurar que aprenda de ambas fuentes y generalice bien. \n",
    "   - **Monitoreo del Rendimiento**: Visualizar las métricas de pérdida y precisión en el conjunto de validación. Implementar técnicas como el early stopping para detener el entrenamiento cuando la mejora se detenga.\n",
    "\n",
    "5. **Evaluación del Modelo**\n",
    "   - **Evaluación en el Conjunto de Prueba**: Evaluar el modelo utilizando el conjunto de prueba para calcular métricas como precisión, recall, F1-score, y generar una matriz de confusión.\n",
    "   - **Evaluación Diferenciada**: Comparar el rendimiento del modelo en imágenes reales y SVG para asegurar que ambos tipos de datos se manejen correctamente.\n",
    "\n",
    "6. **Guardado y Exportación del Modelo**\n",
    "   - **Guardado del Modelo**: Guardar el modelo entrenado en un formato reutilizable (por ejemplo, `.h5` o `.pb` en Keras).\n",
    "   - **Exportación del Modelo**: Convertir y exportar el modelo en un formato optimizado para inferencia en producción.\n",
    "\n",
    "7. **Implementación y Pruebas del Modelo en Producción**\n",
    "   - **Integración del Modelo**: Desplegar el modelo en un entorno de producción (usando frameworks como Flask, FastAPI o TensorFlow Serving) para inferencia en tiempo real.\n",
    "   - **Pruebas de Inferencia**: Realizar pruebas con nuevas imágenes (tanto reales como SVG) para verificar la precisión y eficiencia del modelo en condiciones reales.\n",
    "\n",
    "Ahora, podemos comenzar con el desarrollo del **Módulo 1: Preparación de los Datos**, que incluirá los pasos específicos para organizar, redimensionar, y normalizar las imágenes. ¿Procedemos con eso?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b2b547-a00b-4036-9a51-1aaacf3f2860",
   "metadata": {},
   "source": [
    "### Uso de SVG en el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3184fe1f-ad6c-42ca-a778-7334955eb7ba",
   "metadata": {},
   "source": [
    "Las imágenes SVG en blanco y negro, con un estilo simple de \"monigote\", representan esquemáticamente las posturas de yoga, mientras que las imágenes PNG que tienes son fotos reales de personas practicando yoga en diferentes ambientes. La diferencia de estilo y complejidad visual entre ambos tipos de imágenes es notable. Esto plantea una pregunta importante sobre la utilidad de los SVG en el proceso de entrenamiento de una red neuronal convolucional (CNN). Aquí algunas formas en que las imágenes SVG pueden ser útiles, así como las consideraciones para decidir si deben o no ser utilizadas:\n",
    "\n",
    "### Utilidad de las Imágenes SVG en el Entrenamiento\n",
    "\n",
    "1. **Aprendizaje de las Características Esenciales de las Posturas**:\n",
    "   - Los SVG simplifican las posturas, mostrando solo las formas y ángulos clave sin distracciones como ropa, fondos o variaciones de luz. Esto puede ayudar al modelo a aprender las características esenciales de cada postura.\n",
    "   - Podrían ser útiles como una forma de preentrenamiento o para reforzar el aprendizaje de las características fundamentales de las posturas.\n",
    "\n",
    "2. **Aumento de la Variedad de Datos**:\n",
    "   - Aunque las imágenes SVG son muy simples comparadas con las imágenes reales, incluirlas en el entrenamiento podría actuar como una forma de regularización, ayudando al modelo a generalizar mejor al aprender a reconocer la postura en un formato simplificado.\n",
    "   - Esto puede ser especialmente útil si el conjunto de imágenes reales no es lo suficientemente grande o variado.\n",
    "\n",
    "3. **Mejora de la Generalización del Modelo**:\n",
    "   - Incluir diferentes tipos de representaciones (fotos reales y dibujos simplificados) puede hacer que el modelo sea más robusto. Si el modelo puede aprender a identificar la postura a partir de representaciones estilizadas, es posible que mejore su capacidad de generalizar cuando se enfrenta a nuevas imágenes que no ha visto antes.\n",
    "\n",
    "### Consideraciones y Desafíos\n",
    "\n",
    "1. **Diferencia en el Dominio de las Imágenes**:\n",
    "   - Las imágenes SVG y las imágenes PNG reales provienen de dominios muy diferentes. Si no se maneja correctamente, esto podría confundir al modelo y afectar su rendimiento en el reconocimiento de imágenes reales.\n",
    "   - Para integrar ambos tipos de imágenes de manera efectiva, podríamos entrenar el modelo en etapas: primero con los SVG para captar las características fundamentales, y luego con las imágenes reales para aprender a aplicarlas en situaciones más complejas.\n",
    "\n",
    "2. **Ajuste del Modelo para Diferentes Estilos de Imágenes**:\n",
    "   - Si se utilizan ambos tipos de imágenes, es importante ajustar la red para que sea capaz de manejar las diferencias visuales. Esto podría incluir técnicas como:\n",
    "     - **Aumento de datos** para las imágenes reales, aplicando transformaciones que simulen estilos simples similares a los SVG.\n",
    "     - **Entrenamiento con un conjunto de datos mixto** en el que se mezcle un balance de SVG y fotos reales para que el modelo aprenda a reconocer posturas en ambos contextos.\n",
    "\n",
    "3. **Preentrenamiento Especializado**:\n",
    "   - Otra estrategia sería usar los SVG solo para preentrenar el modelo en una etapa inicial y luego continuar el entrenamiento solo con imágenes reales. Esto se hace a veces para que el modelo primero aprenda las formas básicas antes de ver las complejidades del mundo real.\n",
    "\n",
    "### Decisión Final\n",
    "\n",
    "Si decides incluir las imágenes SVG en el entrenamiento, sería recomendable:\n",
    "- Evaluar su impacto en el rendimiento del modelo en un experimento controlado (con y sin SVG) para ver si realmente mejoran la precisión y la capacidad de generalización.\n",
    "- Utilizar técnicas de aumento de datos para simular diferentes estilos y asegurar que el modelo no dependa de características específicas de un solo tipo de imagen.\n",
    "\n",
    "En resumen, los SVG pueden ser útiles para reforzar el aprendizaje de características básicas y mejorar la generalización si se manejan adecuadamente. Sin embargo, si las diferencias entre los dominios de las imágenes son demasiado grandes, podría ser más efectivo enfocar el entrenamiento exclusivamente en las imágenes reales.\n",
    "\n",
    "¿Te gustaría seguir incluyendo los SVG en el pipeline o prefieres que enfoquemos el entrenamiento solo con las imágenes PNG reales?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee86c62-a789-43eb-a08f-b4dbba727495",
   "metadata": {},
   "source": [
    "### Módulo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7123ff79-eee6-4659-80f6-c90f9a7ac9da",
   "metadata": {},
   "source": [
    "Para el Módulo 1, vamos a estructurar el código para preparar los datos de manera que podamos trabajar con ambos conjuntos (las imágenes SVG y las imágenes reales en formato PNG). Realizaremos los siguientes pasos:\n",
    "\n",
    "1. **Estandarización y Normalización de Imágenes**: \n",
    "   - Redimensionar todas las imágenes a un tamaño estándar.\n",
    "   - Convertir las imágenes a escala de grises si es necesario (para las SVG) o mantenerlas en color (para las PNG).\n",
    "   - Normalizar los valores de píxel.\n",
    "\n",
    "2. **Cargar y Preprocesar las Imágenes**:\n",
    "   - Cargar las imágenes desde sus rutas (SVG y PNG).\n",
    "   - Asignar etiquetas basadas en el nombre de la postura (en sánscrito) para ambos conjuntos de datos.\n",
    "   - Organizar todo en un DataFrame o una estructura que podamos usar para entrenar el modelo.\n",
    "\n",
    "3. **Dividir el Conjunto de Datos**:\n",
    "   - Dividir el conjunto de datos en entrenamiento, validación y prueba de manera balanceada.\n",
    "\n",
    "Voy a mostrarte el código paso a paso para realizar estos procesos. A continuación, comenzaremos cargando y redimensionando las imágenes:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Cargar el DataFrame de las imágenes SVG\n",
    "DS_PATH = \"../ds\"\n",
    "DS_ENTRY = f\"{DS_PATH}/Poses.json\"\n",
    "\n",
    "with open(DS_ENTRY, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "df = pd.DataFrame(data[\"Poses\"])\n",
    "\n",
    "# Definir el tamaño de las imágenes para estandarización\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "# Función para cargar y procesar las imágenes SVG\n",
    "def process_svg_images(df):\n",
    "    svg_images = []\n",
    "    labels = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        svg_path = row['img_url']  # Ruta de la imagen SVG\n",
    "        sanskrit_name = row['sanskrit_name']\n",
    "        \n",
    "        # Leer la imagen SVG\n",
    "        image = cv2.imread(svg_path, cv2.IMREAD_UNCHANGED)\n",
    "        if image is not None:\n",
    "            # Redimensionar y normalizar\n",
    "            image_resized = cv2.resize(image, IMAGE_SIZE)\n",
    "            image_normalized = image_resized / 255.0  # Normalizar a [0, 1]\n",
    "            svg_images.append(image_normalized)\n",
    "            labels.append(sanskrit_name)\n",
    "        else:\n",
    "            print(f\"Error al cargar la imagen SVG en: {svg_path}\")\n",
    "    \n",
    "    return np.array(svg_images), np.array(labels)\n",
    "\n",
    "# Cargar y procesar imágenes SVG\n",
    "svg_images, svg_labels = process_svg_images(df)\n",
    "\n",
    "# Función para cargar y procesar las imágenes reales en PNG\n",
    "def process_png_images(ds_path):\n",
    "    png_images = []\n",
    "    labels = []\n",
    "    \n",
    "    for folder in os.listdir(ds_path):\n",
    "        folder_path = os.path.join(ds_path, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                if file.endswith('.png'):\n",
    "                    # Leer la imagen PNG\n",
    "                    image = cv2.imread(file_path)\n",
    "                    if image is not None:\n",
    "                        # Redimensionar y normalizar\n",
    "                        image_resized = cv2.resize(image, IMAGE_SIZE)\n",
    "                        image_normalized = image_resized / 255.0  # Normalizar a [0, 1]\n",
    "                        png_images.append(image_normalized)\n",
    "                        labels.append(folder)  # El nombre de la carpeta es la etiqueta (en sánscrito)\n",
    "                    else:\n",
    "                        print(f\"Error al cargar la imagen PNG en: {file_path}\")\n",
    "    \n",
    "    return np.array(png_images), np.array(labels)\n",
    "\n",
    "# Cargar y procesar imágenes PNG\n",
    "png_images, png_labels = process_png_images(DS_PATH)\n",
    "\n",
    "# Combinar ambos conjuntos de datos\n",
    "all_images = np.concatenate((svg_images, png_images), axis=0)\n",
    "all_labels = np.concatenate((svg_labels, png_labels), axis=0)\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento, validación y prueba\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Tamaño del conjunto de validación: {X_val.shape}\")\n",
    "print(f\"Tamaño del conjunto de prueba: {X_test.shape}\")\n",
    "```\n",
    "\n",
    "### Explicación del Código:\n",
    "\n",
    "1. **Carga y Preprocesamiento de Imágenes SVG**:\n",
    "   - `process_svg_images(df)` carga y redimensiona las imágenes SVG utilizando OpenCV y las normaliza al rango [0, 1].\n",
    "   - Las etiquetas (posturas en sánscrito) se asignan basadas en el DataFrame.\n",
    "\n",
    "2. **Carga y Preprocesamiento de Imágenes PNG**:\n",
    "   - `process_png_images(ds_path)` carga las imágenes PNG de las subcarpetas, las redimensiona y normaliza.\n",
    "   - Las etiquetas se extraen del nombre de la carpeta que corresponde a la postura de yoga.\n",
    "\n",
    "3. **Combinación y División del Conjunto de Datos**:\n",
    "   - Combinamos ambos conjuntos de imágenes y etiquetas.\n",
    "   - Usamos `train_test_split` de `sklearn` para dividir el conjunto en entrenamiento (70%), validación (15%), y prueba (15%), asegurando que las proporciones se mantengan balanceadas con `stratify`.\n",
    "\n",
    "Este código prepara los datos para el siguiente paso del pipeline. Puedes ejecutarlo y confirmar que todo funciona correctamente antes de avanzar al Módulo 2: **Aumento de Datos**. ¿Te parece bien continuar de esta forma?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1199fcb9-6148-403c-8577-0772b32c68ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
